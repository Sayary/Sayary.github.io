<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Eggwhite&amp;Yolk/posts/2015-01-16-scalability-fundamentals/</title>
    
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="robots" content="all,follow">
    <meta name="googlebot" content="index,follow,snippet,archive">
    <link rel="stylesheet" href="https://sayary.github.io/hugo-theme-console/css/terminal-0.7.1.min.css">
    <link rel="stylesheet" href="https://sayary.github.io/hugo-theme-console/css/console.css">
    
      <!--[if lt IE 9]>
          <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
          <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
      <![endif]-->
       <meta property="og:title" content="Scalability Fundamentals" />
<meta property="og:description" content="" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://sayary.github.io/posts/2015-01-16-scalability-fundamentals/" /><meta property="article:published_time" content="2015-01-16T12:14:34-07:00" />



<meta name="twitter:title" content="Scalability Fundamentals"/>
<meta name="twitter:description" content="这篇博客主要参考Scalability Fundamentals里的内容，其目的主要是对系统的可扩展性的一些基本概念的简单介绍，我们分为三部分介绍这个专题。"/>

<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-179836662-1', 'auto');
	
	ga('send', 'pageview');
}
</script>

</head>
<body class="terminal">
    <div class="container">
        <div class="terminal-nav">
          <header class="terminal-logo">
            <div class="logo terminal-prompt">
              
              
              <a href="https://sayary.github.io/" class="no-style site-name">Eggwhite&amp;Yolk</a>:~# 
              <a href='https://sayary.github.io/posts'>posts</a>/<a href='https://sayary.github.io/posts/2015-01-16-scalability-fundamentals'>2015-01-16-scalability-fundamentals</a>/</div></header>
          <nav class="terminal-menu">
            <ul vocab="https://schema.org/" typeof="BreadcrumbList">
                
                <li><a href="https://sayary.github.io/posts/" typeof="ListItem">Posts/</a></li>
                
                <li><a href="https://sayary.github.io/tags/" typeof="ListItem">Tags/</a></li>
                
                <li><a href="https://sayary.github.io/photos/" typeof="ListItem">Photos/</a></li>
                
                <li><a href="https://sayary.github.io/about/" typeof="ListItem">About/</a></li>
                
                <li><a href="https://sayary.github.io/index.xml" typeof="ListItem">RSS/</a></li>
                
            </ul>
          </nav>
        </div>
    </div>

    <div class="container animated zoomIn fast">
        
<h1>Scalability Fundamentals</h1>

Jan. 16, 2015 | Words: 3820

<br/><br/>
<p>这篇博客主要参考<a href="http://www.hiredintech.com/app#scalability-fundamentals">Scalability Fundamentals</a>里的内容，其目的主要是对系统的可扩展性的一些基本概念的简单介绍，我们分为三部分介绍这个专题。</p>
<h3 id="1-scalability-harvard-web-development">1. Scalability Harvard Web Development</h3>
<p>第一部分是一个来自于哈佛大学的课堂视频，主要介绍了高扩展性的一些内容，<a href="www.youtube.com/embed/-W9F__D3oY4">视频链接</a></p>
<p>在这里面主要介绍了一下这些基本概念：</p>
<h3 id="11-vertical-scaling">1.1 Vertical Scaling</h3>
<p>纵向扩容主要是提升主机的硬件性能，比如为主机增加跟过的硬盘、缓存、CPU，但是这样做是有上限的，因为摩尔定律使得硬件提升的速度优先，而且最优秀的硬件往往性能提升一点就要额外花费大量金钱，无疑是不能满足需求的。</p>
<h3 id="12-horizontal-scaling">1.2 Horizontal Scaling</h3>
<p>横向扩容其实就是GFS那一套，把多个硬件性能不是那么顶尖的机器组合成集群，通过load balancer合理的分流策略把数据计算分流到不同的机器上，得到与性能强劲的单个机器同样的效果。</p>
<h3 id="13-load-balancing">1.3 Load Balancing</h3>
<p>假设我们接收到来自用户的大量请求，我们怎么样才能把这些请求分流到不同的服务器上呢？如果分流策略设计的不合理就会导致某些server很忙而某些server很闲，无疑是对系统的一种浪费，系统性能也容易到达瓶颈。</p>
<p>一种办法是使用不同的分配策略向不同的服务器上分流，这里的算法与OS中系统进程的调度算法类似，如Round-Robin, 优先队列等等，就不一一赘述了。</p>
<p>另一种办法是设置单独的服务器面向不同的服务类型，如所有图片放到图片服务器，相应的有js服务器，php服务器等等，这样的好处是每种不同类型的网络资源都相对集中，坏处也显而易见，如果没有做好备份的话服务器崩掉所有的服务就都会受到影响，这也就是所谓的<strong>Single point of failure</strong>。</p>
<p>这里我们可以借用RAID来完成系统的备份，RAID分为不同的类型。</p>
<blockquote>
<p>RAID0: strip data，即两个drive交替写入数据，优点是速度较快</p>
</blockquote>
<blockquote>
<p>RAID1: 两个drive同时写入同样的数据，这样一个drive坏掉之后不会影响备份，而且易于替换</p>
</blockquote>
<blockquote>
<p>RAID10: 4个drive，两个为RAID0，两个为RAID1，结合了二者的优点</p>
</blockquote>
<blockquote>
<p>RAID5: 可能有3、4、5个drive交替写入，留下一个drive做备份</p>
</blockquote>
<p>同时，我们也要注意对load balancer进行备份，如果只有一个load balancer的话也可能成为系统的痛点。</p>
<p>一种可能的做法是我们是有两个load balancer，一个为active,一个为passive。平时只有active的load balancer进行工作，两个load balancer之间通过定时的&quot;heart beat&quot;进行通信，一旦passvide的 load balancer一段时间没有收到来自actie load balancer的信号，就判断该load balancer挂掉了，这次passive load balancer会接管负载均衡的工作。</p>
<h3 id="14-caching">1.4 Caching</h3>
<p>缓存的思想不仅仅出现在分布式系统中，在操作系统中同样至关重要，那么为什么caching这么重要呢？ 我们首先要引入Read Heavy和Write Heavy的概念。</p>
<blockquote>
<p><strong>Read Heavy vs Write Heavy</strong>:
如果一个系统的服务主要是读操作，那么我们说它是Read Heavy System, 反之如果主要操作是写操作，那么就是Write Heavy System.</p>
</blockquote>
<p>缓存对于Read-Heavy System至关重要，因为对于某条需要多次重复读取的信息，如果我们每次收到请求都要跑到数据库去查询然后再返回的话，无疑是很浪费时间的。比较好的策略是我们第一次查询这条信息后，就把这条信息存入Cache里，当下次再请求该信息时，直接从Cache返回即可，速度提升十分明显。</p>
<p>但是Cache会引发几个新的问题：</p>
<h4 id="141-cache的空间是有限的如果我的cache满了应该怎么办呢">1.4.1 Cache的空间是有限的，如果我的Cache满了应该怎么办呢？</h4>
<p>这里就需要运用到OS中介绍到的多种Cache更新的策略了，如LRU， MRU， Best, Worst, 2nd Chance等等，可以看出学好OS还是很重要的！</p>
<h4 id="142-sticky-session问题">1.4.2 Sticky Session问题</h4>
<p>其实这个问题是由于Load Balancing带来的，假设我们用load balancing将同样用户的请求分配到不同的sever上，因为server之间是不能通信的，那么随之而来可能造成session在不同server上的重复。我们不想要出现如此多的重复session，有什么解决办法呢？</p>
<p>一种办法是我单独建一个server存放所有session，这样就不会出现重复了，但是这样做有一个弊端：如果我的session server挂了所有session就全完了，补救的办法是可以做backup，这是很常用的补救措施。</p>
<p>还有一种办法，我们通过cookies来保存一个用户上次被分配到的server，这样用户下一次调请求时，load balancer可以通过cookies中的信息分配到上一次处理用户请求的sever上去。这样做的问题是：</p>
<ol>
<li>cookies上面maybe不能存放足够多的信息</li>
<li>我们不应该把server的相关信息暴漏给外界，这是不合理也是不安全的。补救方法是：我们不从cookies中保存相关server信息，而是保存随机数，然后再load balancer建表来表示随机数与相关server的关系，相当于一个大的hash table。</li>
</ol>
<h3 id="15-database-replication">1.5 Database Replication</h3>
<p>说完了应用层，我们再来说数据存储层。</p>
<p>在数据层，我们同样需要采用分布式架构，一种常见的结构是Master-Slave结构，即Master作为集群的中心节点，分布式的存储数据信息，将数据存储到不同的db上。</p>
<p>然而数据存储层无疑也会出现Single point of failure, 即我们在数据存储层同样需要做Replications.
由此演化而来的结构就是Master-Master结构，这里对Master节点做了备份，以防止某个Master节点突然崩溃。</p>
<h3 id="16-database-partitioning">1.6 Database Partitioning</h3>
<p>在完成了以上步骤之后，我们的系统大致是这样的：</p>
<p>这已经是一个相对完善的方案了，唯一的可以优化的地方就是在数据操作的负载均衡时，我们能否借鉴应用层的思想，将不同类型的数据分门别类的分配到不同的DB上，这就是Partition的思想，具体结构如下：</p>
<p>可以看到，我们把数据分为A-M 以及 N-Z两部分，这样通过进一步划分提高了系统的效率，有点类似于建索引的作用。</p>
<h3 id="2-scalability-for-dummies">2. Scalability for Dummies</h3>
<p>第二部分主要是4篇关于<a href="http://www.lecloud.net/post/7295452622/scalability-for-dummies-part-1-clones">Scalability for Dummies</a>的博客，下面分别摘要一下四篇文章的内容：</p>
<h3 id="21-scalability-for-dummies---part-1-clones">2.1 Scalability for Dummies - Part 1: Clones</h3>
<p>第一篇主要介绍了系统在可扩展性方面的知识，其中有一点十分重要，那就是</p>
<blockquote>
<p>Every server contains exactly the same codebase and does not store any user-related data, like sessions or profile pictures, on local disc or memory.</p>
</blockquote>
<p>这其实就是前面说的Sticky Session的道理，我们应当保证server是无状态的，这样才能够在需要的时候快速添加新的服务集群，那么具体是怎么做到的呢？</p>
<blockquote>
<p>After “outsourcing” your sessions and serving the same codebase from all your servers, you can now create an image file from one of these servers (AWS calls this AMI - Amazon Machine Image.) Use this AMI as a “super-clone” that all your new instances are based upon. Whenever you start a new instance/clone, just do an initial deployment of your latest code and you are ready!</p>
</blockquote>
<p>简而言之，意思就是说，当我们把session单独抽离出来放到独立的server上之后，整个系统集群就是无状态的了。此时我们为集群创造一个镜像文件，一旦我们需要添加集群，只需要根据镜像文件boot就可以，这样可以保证所有集群codebase的一致性。</p>
<h3 id="22-scalability-for-dummies---part-2-database">2.2 Scalability for Dummies - Part 2: Database</h3>
<p>这篇文章总结起来就是一句话：NoSQL大法好！</p>
<p>原文的主要意思是说，随着数据量的增长，在关系型数据库中通过Joins合并数据的方法会使得系统的反馈速度越来越慢，我们应当在数据量不大的早期就开始向NoSQL迁移，将数据合并的工作放到代码中而不是在数据库中解决。</p>
<h3 id="23-scalability-for-dummies---part-3-cache">2.3 Scalability for Dummies - Part 3: Cache</h3>
<p>第三部分主要讲到了缓存的作用，同时提到了刚才忽略的一点，</p>
<blockquote>
<p>Never do file-based caching</p>
</blockquote>
<p>意思就是说不要缓存文件而是缓存内容，缓存文件的意思就是说比如生成的所有html都缓存下来，相当于静态文件，这样不仅占用大量空间，而且不利用代码的复用和修改。</p>
<p>同时，文章中还提到了两种Caching的方式，我暂时没有很理解第二种方法，就先把它摘录在这里。</p>
<p>第一种方法比较直接，<strong>就是Cached Database Queries</strong>。意思就是说每次我通过SQL语句查询回的结果，就进行缓存操作。这种方式十分常见但是有一个很大的缺点，如果我对数据库做了一定的内容修改，比如插入或者删除数据，我必须要更新cache中的数据，因为原来的结果已经不对了，这无疑是一个非常expensive的操作。</p>
<p>第二种方法是<strong>Cached Objects</strong>，具体解释如下：</p>
<blockquote>
<p>hat’s my strong recommendation and I always prefer this pattern. In general, see your data as an object like you already do in your code (classes, instances, etc.). Let your class assemble a dataset from your database and then store the complete instance of the class or the assembed dataset in the cache. Sounds theoretical, I know, but just look how you normally code. You have, for example, a class called “Product” which has a property called “data”. It is an array containing prices, texts, pictures, and customer reviews of your product. The property “data” is filled by several methods in the class doing several database requests which are hard to cache, since many things relate to each other. Now, do the following: when your class has finished the “assembling” of the data array, directly store the data array, or better yet the complete instance of the class, in the cache! This allows you to easily get rid of the object whenever something did change and makes the overall operation of your code faster and more logical.</p>
</blockquote>
<p>最后提到了通过Cached Objects的方法，使得异步编程成为了可能，并且列举了一些需要cache的使用场景，如:</p>
<ul>
<li>user sessions (never use the database!)</li>
<li>fully rendered blog articles</li>
<li>activity streams</li>
<li>user&lt;-&gt;friend relationships</li>
</ul>
<p>同时，作者还对不同的缓存Redis和Memcached做了比较：</p>
<blockquote>
<p>I am more a friend of Redis than Memcached, because I love the extra database-features of Redis like persistence and the built-in data structures like lists and sets. With Redis and a clever key’ing there may be a chance that you even can get completly rid of a database. But if you just need to cache, take Memcached, because it scales like a charm.</p>
</blockquote>
<h3 id="24-scalability-for-dummies---part-4-asynchronism">2.4 Scalability for Dummies - Part 4: Asynchronism</h3>
<p>这篇博客主要介绍了异步的基本概念，里面举的面包房的例子十分生动形象，如果看不太懂的话可以同时参考<a href="http://highscalability.com/blog/2009/8/6/an-unorthodox-approach-to-database-design-the-coming-of-the.html">知乎</a>的这个答案，有异曲同工之效。</p>
<h3 id="3-database-sharding">3. Database sharding</h3>
<p>第三部分同样是一篇博客，主要普及了关于<a href="http://highscalability.com/blog/2009/8/6/an-unorthodox-approach-to-database-design-the-coming-of-the.html">Database sharding</a>的内容。</p>
<script src="https://utteranc.es/client.js"
        repo="Sayary/Sayary.github.io"
        issue-term="title"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script>

        

    </div>
  </body>
</html>
